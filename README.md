
# ğŸ“Œ **TP Final â€“ ProgramaciÃ³n Avanzada**

## **PredicciÃ³n del precio de propiedades en CABA usando XGBoost + CatBoost**

**Autor:** *Asado Analytics*
**AÃ±o:** 2025

**Integrantes:** 
  - GastÃ³n Conessa
  - Fernando Nieto Benavidez
  - Alan Aramayo
  - Alejandro Sacndinaro
  - Juan Ignacio Failache

---

# ğŸ§  **DescripciÃ³n general del proyecto**

Este trabajo prÃ¡ctico implementa un **pipeline completo de Ciencia de Datos y Machine Learning**, cuyo objetivo es **predecir el precio de propiedades residenciales en CABA** utilizando datos del dataset **Properati Argentina** (Kaggle).

El proyecto incluye:

âœ” Descarga automÃ¡tica de datos desde Kaggle
âœ” ETL + limpieza avanzada
âœ” Geofiltrado con GeoPandas
âœ” DetecciÃ³n de outliers por tipo de propiedad
âœ” ConstrucciÃ³n de features geoespaciales
âœ” Cross-Validation estratificada por rangos de precio
âœ” ComparaciÃ³n de modelos: **XGBoost vs. CatBoost**
âœ” Entrenamiento final del mejor modelo (**XGBoost**)
âœ” ExportaciÃ³n de artefactos `.pkl`
âœ” Almacenamiento completo en **SQLite**
âœ” GeneraciÃ³n de grÃ¡ficos de mÃ©tricas
âœ” Dashboard funcional en **Streamlit** para probar el modelo

---

# ğŸ¯ **Objetivos del trabajo**

### âœ” ConstrucciÃ³n del modelo

* Implementar **pipelines de preprocesamiento**.
* Comparar al menos **dos modelos de regresiÃ³n** (XGBoost y CatBoost).
* Usar mÃ©tricas: **MAE, RMSE, RÂ²**.
* Realizar **Cross-Validation estratificada** para evitar fuga de informaciÃ³n.

### âœ” Persistencia en Base de Datos

Toda la informaciÃ³n se guarda en SQLite:

| Tabla                   | DescripciÃ³n                      |
| ----------------------- | -------------------------------- |
| **datos_raw**           | CSV de Kaggle sin procesar       |
| **datos_limpios**       | Dataset filtrado y curado        |
| **resultados_por_fold** | MÃ©tricas de CV por fold          |
| **resultados_modelo**   | MÃ©tricas promedio por modelo     |
| **config_modelo**       | ParÃ¡metros de XGBoost y CatBoost |

### âœ” Visualizaciones

Se generan grÃ¡ficos automÃ¡ticos:

* RMSE por fold
* RMSE promedio por modelo
* MAE promedio por modelo
* RÂ² promedio por modelo

### âœ” ExportaciÃ³n del modelo final

* `modelo_xgboost_final.pkl`
* `kmeans_final.pkl`
* `precio_m2_barrio_final.pkl`
* `zona_premium_map_final.pkl`
* `xgb_feature_names.pkl`

---

# ğŸ“ **Estructura del proyecto**

```
tp_programacion/
â”‚
â”œâ”€â”€ data/                         # CSV descargados desde Kaggle
â”œâ”€â”€ inmuebles.db                  # Base SQLite con todo el pipeline
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ db_utils.py               # CreaciÃ³n/lectura de SQLite
â”‚   â”œâ”€â”€ data_pipeline.py          # ETL + limpieza + geofiltrado
â”‚   â”œâ”€â”€ model_pipeline.py         # CV, mÃ©tricas y modelos
â”‚
â”œâ”€â”€ main.py                       # Ejecuta TODO el pipeline end-to-end
â”œâ”€â”€ visualize_metrics.py          # GrÃ¡ficos de mÃ©tricas
â”‚
â”œâ”€â”€ modelo_xgboost_final.pkl      # Modelo final exportado
â”œâ”€â”€ kmeans_final.pkl
â”œâ”€â”€ precio_m2_barrio_final.pkl
â”œâ”€â”€ zona_premium_map_final.pkl
â”œâ”€â”€ xgb_feature_names.pkl
â”‚-- caba.json                    # geojson para hacer filtrado espacial
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md                     # Este archivo
```

---

# ğŸš€ **Flujo completo del pipeline**

El proyecto estÃ¡ diseÃ±ado para correr **con un solo comando**:

```
python main.py
```

### Lo que hace:

### **1) Descarga el Dataset**

Usa `kagglehub` para bajar:

```
properati-argentina-dataset
```

Luego **copia esos CSV a la carpeta local `/data`** del proyecto.

Si no trae el csv de Kaggle descargarlo de la pagina :https://www.kaggle.com/datasets/alejandroczernikier/properati-argentina-dataset

y dejarlo en carpeta DATA
---

### **2) ETL + Limpieza**

Incluye:

* CorrecciÃ³n de lat/lon invertidos
* ConversiÃ³n ARS â†’ USD 2019 / 2020
* EliminaciÃ³n de columnas irrelevantes
* ValidaciÃ³n geogrÃ¡fica contra `caba.json`
* Limpieza numÃ©rica fuerte
* Outliers por tipo de propiedad (IQR)
* Filtro: solo propiedades residenciales

El dataset final se guarda en:

ğŸ“Œ `datos_limpios` (â‰ˆ 93.000 filas)

---

### **3) GeneraciÃ³n del dataset de CV**

Se aplica una limpieza adicional:

* Filtrado por precio/mÂ² fuera del 1%-99%
* Solo filas confiables

ğŸ“Œ Resultado: **aprox. 71.718 registros**
Este dataset se usa tanto para **CV** como para el **modelo final**.

---

### **4) Cross-Validation estratificada**

* EstratificaciÃ³n por quintiles de precio.
* ConstrucciÃ³n de features sin leakage:

  * `precio_m2_barrio`
  * `zona_premium (0â€“3)`
  * `cluster_geo` con KMeans
* ComparaciÃ³n de:

  * **XGBoost**
  * **CatBoost**

Cada fold genera: MAE, RMSE, RÂ².

Se guardan en:

ğŸ“Œ `resultados_por_fold`
ğŸ“Œ `resultados_modelo`
ğŸ“Œ `config_modelo`

---

### **5) Entrenamiento final del mejor modelo**

El modelo ganador fue:

## â­ **XGBoost**

Se entrena con las mismas 71.718 filas usadas para CV.

Se exportan todos los artefactos a `.pkl` para producciÃ³n.

---

### **6) VisualizaciÃ³n de mÃ©tricas**

Se corre con:

```
python visualize_metrics.py
```

Genera:

* `figures/rmse_por_fold.png`
* `figures/rmse_por_modelo.png`
* `figures/mae_por_modelo.png`
* `figures/r2_por_modelo.png`

---

# â–¶ï¸ **CÃ³mo ejecutar localmente**

### 1) Crear entorno y activar

```
python -m venv venv
source venv/bin/activate     # Linux / Mac
venv\Scripts\activate        # Windows
```

### 2) Instalar dependencias

```
pip install -r requirements.txt
```

### 3) Ejecutar todo el pipeline

```
python main.py
```

### 4) Visualizar mÃ©tricas

```
python visualize_metrics.py
```

---

# ğŸŒ **Deploy en Streamlit (segundo repositorio)**

Este proyecto fue complementado con un repositorio aparte donde se implementÃ³ una **aplicaciÃ³n Streamlit** para consumir el modelo final entrenado.

### ğŸ”— **Repositorio del deploy**

ğŸ‘‰ [https://github.com/R3ptiliaNo/prediccion-inmuebles](https://github.com/R3ptiliaNo/prediccion-inmuebles)

### ğŸ”— **App online funcionando**

ğŸ‘‰ [https://prediccion-inmuebles-caba.streamlit.app/#prediccion-de-precio-de-propiedades-en-caba](https://prediccion-inmuebles-caba.streamlit.app/#prediccion-de-precio-de-propiedades-en-caba)

La app permite:

* Cargar ubicaciÃ³n, ambientes, superficie y tipo de propiedad
* Preprocesar la entrada con los mismos steps del pipeline
* Generar predicciones utilizando el modelo exportado `.pkl`


---

# ğŸ **Conclusiones**

El proyecto cumple con:

âœ” Buenas prÃ¡cticas de organizaciÃ³n y modularizaciÃ³n
âœ” Pipelines claros de ETL y modelado
âœ” EvaluaciÃ³n rigurosa con CV estratificada
âœ” ComparaciÃ³n transparente de modelos
âœ” Persistencia completa en SQLite
âœ” Visualizaciones para anÃ¡lisis
âœ” Modelo deployado en la web para validaciÃ³n real

El flujo desde datos en crudo â†’ modelo final â†’ app web estÃ¡ completamente integrado, profesional y reproducible.

---


